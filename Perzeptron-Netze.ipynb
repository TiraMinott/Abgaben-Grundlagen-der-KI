{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbadb2b9-4ac3-41e1-b654-5fba30e55311",
   "metadata": {},
   "source": [
    "## NN.MLP.01: Perzeptron-Netze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6859fdb-571a-486c-826c-3aad95e80243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sign(x):\n",
    "    # Ausgabe genau in {-1, +1}\n",
    "    return np.where(x >= 0, 1, -1)\n",
    "\n",
    "#Perzeptron-Netz (3 Perzeptrons)\n",
    "# h1 = sign(x2 - 3)  -> +1, wenn x2 >= 3\n",
    "# h2 = sign(x1 - 2)  -> +1, wenn x1 >= 2\n",
    "# y  = sign(h1 + h2 + 1)  -> OR-Verknüpfung\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\"\n",
    "    X: array shape (n, 2) mit Spalten [x1, x2]\n",
    "    return: array shape (n,) in {-1, +1}\n",
    "    \"\"\"\n",
    "    x1 = X[:, 0]\n",
    "    x2 = X[:, 1]\n",
    "\n",
    "    h1 = sign(x2 - 3)          # w=(0,1), b=-3\n",
    "    h2 = sign(x1 - 2)          # w=(1,0), b=-2\n",
    "    y  = sign(h1 + h2 + 1)     # w=(1,1), b=+1\n",
    "\n",
    "    return y\n",
    "\n",
    "# Test\n",
    "test_points = np.array([\n",
    "    [0, 0],     # im dunklen Block -> -1\n",
    "    [0, 4],     # oben (x2>=3) -> +1\n",
    "    [3, 0],     # rechts (x1>=2) -> +1\n",
    "    [3, 4],     # beides -> +1\n",
    "])\n",
    "print(predict(test_points))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ab90b-2733-428f-a6f9-1ae23a4df42a",
   "metadata": {},
   "source": [
    "### NN.MLP.02: Vorwärtslauf im MLP\n",
    "\n",
    "Gegeben ist ein MLP mit 25 Zellen in der Eingabeschicht,  \n",
    "64 Zellen in der ersten versteckten Schicht,  \n",
    "32 Zellen in der zweiten versteckten Schicht und  \n",
    "4 Zellen in der Ausgabeschicht.  \n",
    "Bias-Zellen werden nicht mitgezählt. In allen Zellen wird die ReLU-Aktivierungsfunktion verwendet.\n",
    "\n",
    "\n",
    "\n",
    "### Dimensionen der Gewichtsmatrizen und Bias-Vektoren\n",
    "\n",
    "Es gilt die Vorwärtslauf-Gleichung\n",
    "\\[\n",
    "z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}.\n",
    "\\]\n",
    "\n",
    "Damit ergeben sich:\n",
    "\n",
    "- $W^{[1]} \\in \\mathbb{R}^{64 \\times 25}$,  \n",
    "  $b^{[1]} \\in \\mathbb{R}^{64 \\times 1}$\n",
    "\n",
    "- $W^{[2]} \\in \\mathbb{R}^{32 \\times 64}$,  \n",
    "  $b^{[2]} \\in \\mathbb{R}^{32 \\times 1}$\n",
    "\n",
    "- $W^{[3]} \\in \\mathbb{R}^{4 \\times 32}$,  \n",
    "  $b^{[3]} \\in \\mathbb{R}^{4 \\times 1}$\n",
    "\n",
    "\n",
    "\n",
    "### Vorwärtslauf in Matrix-Notation\n",
    "\n",
    "Für einen Eingabevektor $x \\in \\mathbb{R}^{25 \\times 1}$ mit $a^{[0]} = x$ gilt:\n",
    "\n",
    "- $z^{[1]} = W^{[1]} a^{[0]} + b^{[1]}$,  \n",
    "  $a^{[1]} = \\mathrm{ReLU}(z^{[1]})$\n",
    "\n",
    "- $z^{[2]} = W^{[2]} a^{[1]} + b^{[2]}$,  \n",
    "  $a^{[2]} = \\mathrm{ReLU}(z^{[2]})$\n",
    "\n",
    "- $z^{[3]} = W^{[3]} a^{[2]} + b^{[3]}$,  \n",
    "  $a^{[3]} = \\mathrm{ReLU}(z^{[3]})$\n",
    "\n",
    "Die Ausgabe des Netzes ist der Vektor $a^{[3]} \\in \\mathbb{R}^{4 \\times 1}$.\n",
    "\n",
    "\n",
    "\n",
    "### Interpretation der Ausgabe\n",
    "\n",
    "Die Ausgabeschicht besitzt vier Neuronen mit ReLU-Aktivierung, sodass die\n",
    "Ausgabe aus vier nichtnegativen Werten besteht.  \n",
    "Das Netzwerk eignet sich daher beispielsweise für ein Multi-Output-\n",
    "Regressionsproblem mit vier Zielgrößen oder zur Berechnung von vier\n",
    "Aktivierungs- bzw. Score-Werten in einem Klassifikationsproblem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74407cdc-e770-43d2-bcb9-bb789a4742af",
   "metadata": {},
   "source": [
    "## NN.MLP.03: Tensorflow Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a656e1a-77c7-4904-a2ce-eded18060bba",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db4818-30c5-46c3-a71d-bfd189c4eead",
   "metadata": {},
   "source": [
    "![Mein Bild](regressionsmodell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e5e9a-89a9-4637-80aa-f89a4630f439",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Die Entscheidungsgrenze ist linear und entspricht einer Geraden. Der Gaussian-Datensatz ist annähernd linear separierbar, sodass die Klassen gut getrennt werden können.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Trainings- und Testkosten sinken schnell und bleiben auf einem ähnlichen Niveau. Es tritt keine Überanpassung auf.\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Die Entscheidungsgrenze wird sehr schnell berechnet, da das Modell nur wenige Parameter besitzt.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Nahezu alle Datenpunkte können korrekt klassifiziert werden. Einzelne Fehlklassifikationen können durch Überlappungen der gaußförmigen Verteilungen entstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac0444-0591-4d8a-841e-e490a577f43e",
   "metadata": {},
   "source": [
    "### Fazit: XOR-Datensatz mit logistischer Regression\n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Die Entscheidungsgrenze ist linear und kann die XOR-Struktur nicht korrekt abbilden. Eine einzelne Gerade reicht nicht aus, um die diagonal angeordneten Klassen zu trennen.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Trainings- und Testkosten bleiben relativ hoch und liegen nahe beieinander. Es tritt keine Überanpassung auf, da das Modell zu einfach ist und die Datenstruktur nicht erfassen kann (Underfitting).\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Die Entscheidungsgrenze wird sehr schnell berechnet, da keine versteckten Schichten vorhanden sind und nur wenige Parameter gelernt werden.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Nein, nicht alle Datenpunkte können korrekt klassifiziert werden. Der XOR-Datensatz ist nicht linear separierbar, weshalb logistische Regression grundsätzlich ungeeignet ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334b6b6-98b4-4843-a6b5-57318ac161a0",
   "metadata": {},
   "source": [
    "### Fazit: Circle-Datensatz mit logistischer Regression\n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Die Entscheidungsgrenze ist linear und kann die ringförmige Struktur des Circle-Datensatzes nicht abbilden. Eine einzelne Gerade ist nicht ausreichend, um innere und äußere Klasse zu trennen.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Trainings- und Testkosten bleiben relativ hoch und liegen nahe beieinander. Es tritt keine Überanpassung auf, da das Modell zu wenig Kapazität besitzt und die Datenstruktur nicht erfassen kann (Underfitting).\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Die Entscheidungsgrenze wird sehr schnell berechnet, da das Modell keine versteckten Schichten enthält und nur wenige Parameter lernt.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Nein, nicht alle Datenpunkte können korrekt klassifiziert werden. Der Circle-Datensatz ist nicht linear separierbar, weshalb logistische Regression für dieses Problem ungeeignet ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7d2a9-d81e-474d-a86f-5a878ec4f4f7",
   "metadata": {},
   "source": [
    "### Fazit: Spiral-Datensatz mit logistischer Regression\n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Die Entscheidungsgrenze ist linear und kann die spiralförmige Struktur des Datensatzes nicht abbilden. Eine einzelne Gerade ist nicht ausreichend, um die ineinander verschlungenen Klassen zu trennen.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Trainings- und Testkosten bleiben relativ hoch und unterscheiden sich nur geringfügig. Es tritt keine Überanpassung auf, da das Modell zu einfach ist und die komplexe Datenstruktur nicht erfassen kann (Underfitting).\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Die Entscheidungsgrenze wird sehr schnell berechnet, da keine versteckten Schichten vorhanden sind und nur wenige Parameter gelernt werden.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Nein, nicht alle Datenpunkte können korrekt klassifiziert werden. Der Spiral-Datensatz ist stark nichtlinear separierbar, weshalb logistische Regression für dieses Problem ungeeignet ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba94843-8e91-4d89-9861-7d34a09c50d1",
   "metadata": {},
   "source": [
    "### Fazit: 1 Hidden Layer mit 2 Neuronen \n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Mit einem versteckten Layer und zwei Neuronen ist die Entscheidungsgrenze bereits nichtlinear.  \n",
    "Beim Circle-Datensatz kann die ringförmige Struktur teilweise erfasst werden, jedoch bleibt die Trennung ungenau.  \n",
    "Beim Spiral-Datensatz reicht die Modellkapazität nicht aus, um die komplexe spiralförmige Struktur korrekt abzubilden.  \n",
    "ReLU erzeugt eher kantige, stückweise lineare Grenzen, während tanh und Sigmoid glattere Entscheidungsgrenzen liefern.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Die Trainings- und Testkosten sinken im Vergleich zur logistischen Regression deutlich, bleiben jedoch bei Spiral relativ hoch.  \n",
    "Trainings- und Testkosten liegen nahe beieinander, sodass keine Überanpassung auftritt.  \n",
    "Insgesamt zeigt sich weiterhin Underfitting, insbesondere beim Spiral-Datensatz.\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Das Training erfolgt schnell. ReLU konvergiert meist am schnellsten, während Sigmoid und tanh etwas langsamer lernen.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Nein, nicht alle Datenpunkte können korrekt klassifiziert werden.  \n",
    "Die geringe Anzahl an Neuronen reicht nicht aus, um die komplexen nichtlinearen Strukturen vollständig zu modellieren, insbesondere beim Spiral-Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383f817-657c-4a21-984b-c8f0623a8333",
   "metadata": {},
   "source": [
    "### Fazit: 1 Hidden Layer mit 3 Neuronen \n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Mit drei Neuronen im versteckten Layer wird die Entscheidungsgrenze deutlich flexibler.  \n",
    "Beim Circle-Datensatz kann die ringförmige Struktur nun größtenteils korrekt erfasst werden.  \n",
    "Beim Spiral-Datensatz wird die spiralförmige Struktur besser angenähert, jedoch noch nicht vollständig nachgezeichnet.  \n",
    "ReLU erzeugt eher kantige, polygonartige Grenzen, während tanh und Sigmoid glattere und besser an die Daten angepasste Entscheidungsgrenzen liefern.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Die Trainings- und Testkosten sinken im Vergleich zum Modell mit zwei Neuronen deutlich.  \n",
    "Beim Circle-Datensatz sind beide Kosten sehr niedrig und ähnlich, was auf eine gute Generalisierung hinweist.  \n",
    "Beim Spiral-Datensatz bleiben die Kosten höher, liegen jedoch weiterhin nahe beieinander, sodass keine Überanpassung auftritt.\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Das Training verläuft weiterhin schnell. ReLU konvergiert am schnellsten, während tanh und insbesondere Sigmoid etwas mehr Epochen benötigen.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Beim Circle-Datensatz können nahezu alle Datenpunkte korrekt klassifiziert werden.  \n",
    "Beim Spiral-Datensatz ist eine vollständige korrekte Klassifikation noch nicht möglich, da die Modellkapazität für die komplexe Struktur weiterhin begrenzt ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22012c9a-227b-45f6-bc07-a4c69970c067",
   "metadata": {},
   "source": [
    "### Fazit: 1 Hidden Layer mit 5 Neuronen \n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Mit fünf Neuronen im versteckten Layer ist die Entscheidungsgrenze deutlich komplexer und flexibel.  \n",
    "Beim Circle-Datensatz kann die ringförmige Struktur sehr gut und nahezu vollständig abgebildet werden.  \n",
    "Beim Spiral-Datensatz wird die spiralförmige Struktur nun deutlich besser nachgezeichnet, auch wenn kleinere Ungenauigkeiten verbleiben.  \n",
    "ReLU führt zu stückweise linearen, teilweise kantigen Grenzen, während tanh und Sigmoid glattere und natürlicher wirkende Entscheidungsgrenzen erzeugen.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Die Trainings- und Testkosten sind beim Circle-Datensatz sehr niedrig und liegen eng beieinander, was auf eine gute Generalisierung hindeutet.  \n",
    "Beim Spiral-Datensatz sinken die Trainingskosten deutlich, während die Testkosten höher bleiben, jedoch ohne starkes Auseinanderdriften.  \n",
    "Eine ausgeprägte Überanpassung ist nicht zu beobachten.\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Das Training ist weiterhin effizient. ReLU konvergiert am schnellsten, während tanh und Sigmoid etwas mehr Epochen benötigen, jedoch stabil lernen.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Beim Circle-Datensatz können nahezu alle Datenpunkte korrekt klassifiziert werden.  \n",
    "Beim Spiral-Datensatz ist eine vollständige korrekte Klassifikation weitgehend möglich, jedoch aufgrund der komplexen Struktur nicht in jedem Fall perfekt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4855a1-5dc9-43fc-909f-e5d3cc1848e8",
   "metadata": {},
   "source": [
    "### Fazit: 2 Hidden Layers mit jeweils 5 Neuronen\n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Durch zwei versteckte Schichten mit jeweils fünf Neuronen wird die Entscheidungsgrenze sehr flexibel und komplex.  \n",
    "Beim Circle-Datensatz kann die ringförmige Struktur nahezu perfekt und stabil abgebildet werden.  \n",
    "Beim Spiral-Datensatz wird die spiralförmige Struktur deutlich besser modelliert als mit nur einer versteckten Schicht, die Entscheidungsgrenze folgt den Windungen größtenteils korrekt.  \n",
    "ReLU erzeugt weiterhin eher stückweise lineare Grenzen, während tanh und Sigmoid sehr glatte und fein angepasste Entscheidungsgrenzen liefern.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Die Trainings- und Testkosten sind beim Circle-Datensatz extrem niedrig und nahezu identisch, was auf eine sehr gute Generalisierung hinweist.  \n",
    "Beim Spiral-Datensatz sinken die Trainingskosten stark, während die Testkosten etwas höher bleiben, jedoch ohne starkes Auseinanderdriften.  \n",
    "Eine deutliche Überanpassung ist nicht zu beobachten, trotz der erhöhten Modellkomplexität.\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Das Training benötigt etwas mehr Epochen als bei flacheren Netzen, bleibt jedoch insgesamt effizient.  \n",
    "ReLU konvergiert am schnellsten, während tanh und Sigmoid langsamer, aber stabil trainieren.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Beim Circle-Datensatz können nahezu alle Datenpunkte korrekt klassifiziert werden.  \n",
    "Beim Spiral-Datensatz ist eine weitgehend korrekte Klassifikation möglich, jedoch bleiben vereinzelt Fehlklassifikationen aufgrund der sehr komplexen Struktur bestehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e8c8b-75ad-4f6b-b4b1-4818d3c049ca",
   "metadata": {},
   "source": [
    "### Fazit: 3 Hidden Layers mit jeweils 7 Neuronen \n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Durch drei versteckte Schichten mit jeweils sieben Neuronen wird eine sehr komplexe und fein strukturierte Entscheidungsgrenze gelernt.  \n",
    "Beim Circle-Datensatz wird die ringförmige Struktur nahezu perfekt und sehr stabil abgebildet.  \n",
    "Beim Spiral-Datensatz kann die spiralförmige Struktur weitgehend korrekt nachvollzogen werden, die Entscheidungsgrenze folgt den Windungen sehr eng.  \n",
    "ReLU erzeugt eher segmentierte, stückweise lineare Grenzen, während tanh besonders glatte und gut angepasste Entscheidungsgrenzen liefert. Sigmoid zeigt tendenziell weniger stabile Ergebnisse.\n",
    "\n",
    "**Trainings- und Testkosten / Überanpassung:**  \n",
    "Beim Circle-Datensatz sind Trainings- und Testkosten extrem niedrig und nahezu identisch, was auf eine sehr gute Generalisierung hinweist.  \n",
    "Beim Spiral-Datensatz sinken die Trainingskosten stark, während die Testkosten höher bleiben. In einigen Konfigurationen deutet der Abstand zwischen Trainings- und Testkosten auf beginnende Überanpassung hin, jedoch ohne extremes Overfitting.\n",
    "\n",
    "**Berechnungsgeschwindigkeit:**  \n",
    "Das Training benötigt aufgrund der hohen Modellkomplexität mehr Epochen als bei flacheren Netzen.  \n",
    "ReLU konvergiert am schnellsten, tanh etwas langsamer, während Sigmoid am langsamsten trainiert.\n",
    "\n",
    "**Korrekte Klassifikation aller Datenpunkte:**  \n",
    "Beim Circle-Datensatz können nahezu alle Datenpunkte korrekt klassifiziert werden.  \n",
    "Beim Spiral-Datensatz ist eine weitgehend korrekte Klassifikation möglich, jedoch bleiben vereinzelt Fehlklassifikationen bestehen, insbesondere bei Rand- und Übergangsbereichen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684606a6-12bf-49ec-9fa8-52d3a267af33",
   "metadata": {},
   "source": [
    "### Fazit:4 Hidden Layers mit 7 Neuronen \n",
    "\n",
    "**Entscheidungsgrenze:**  \n",
    "Das Netzwerk mit vier versteckten Schichten und jeweils sieben Neuronen ist in der Lage, eine sehr komplexe und feingranulare Entscheidungsgrenze zu lernen.  \n",
    "Die nichtlinearen Strukturen des Datensatzes (z. B. Kreis- bzw. Spiralform) werden nahezu vollständig korrekt erfasst.\n",
    "\n",
    "**Trainings- und Testkosten:**  \n",
    "Die Trainingskosten sinken sehr schnell auf nahezu 0, was auf eine hohe Modellkapazität hinweist.  \n",
    "Die Testkosten sind abhängig von der Aktivierungsfunktion:\n",
    "- Mit ReLU und Tanh bleiben Trainings- und Test-Loss sehr niedrig.\n",
    "- Mit Sigmoid sind Trainings- und Test-Loss deutlich höher und das Lernen instabiler.\n",
    "\n",
    "**Überanpassung:**  \n",
    "Aufgrund der hohen Modellkomplexität besteht grundsätzlich die Gefahr der Überanpassung.  \n",
    "In den gezeigten Experimenten ist diese jedoch nur gering ausgeprägt, da Trainings- und Test-Loss meist ähnlich niedrig sind.  \n",
    "Bei ungünstiger Aktivierungsfunktion (Sigmoid) zeigt sich jedoch eine schlechtere Generalisierung.\n",
    "\n",
    "**Berechnung der Entscheidungsgrenze:**  \n",
    "Die Entscheidungsgrenze benötigt mehr Epochen zur Konvergenz als bei flacheren Netzen, wird danach jedoch sehr stabil und präzise.  \n",
    "Der Rechenaufwand ist höher, aber gerechtfertigt durch die deutlich bessere Modellleistung.\n",
    "\n",
    "**Klassifikationsfähigkeit:**  \n",
    "Mit dieser Architektur können nahezu alle Datenpunkte korrekt klassifiziert werden.  \n",
    "Dies ist möglich, da das tiefe Netzwerk hochkomplexe nichtlineare Zusammenhänge modellieren kann.\n",
    "\n",
    "**Zusammenfassung:**  \n",
    "Ein MLP mit vier Hidden Layers und sieben Neuronen pro Schicht eignet sich sehr gut für stark nichtlineare Datensätze.  \n",
    "Die besten Ergebnisse werden mit ReLU oder Tanh erzielt, während Sigmoid für tiefe Netze weniger geeignet ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ee087-b335-4b13-b95e-2bc2f69e7ded",
   "metadata": {},
   "source": [
    "### Einfluss der Aktivierungsfunktion \n",
    "die Wahl der Aktivierungsfunktion hat sowohl Einfluss auf die Form der Entscheidungsgrenze als auch auf die Geschwindigkeit der Berechnung.  \n",
    "Nichtlineare Aktivierungsfunktionen wie ReLU und tanh ermöglichen komplexe, stark gekrümmte Entscheidungsgrenzen und führen in der Regel zu einer schnelleren und stabileren Konvergenz.  \n",
    "Die Sigmoid-Funktion lernt deutlich langsamer, neigt bei tiefen Netzen zu Sättigungseffekten und erzeugt oft ungenauere Entscheidungsgrenzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da3135-6576-4aa5-bec4-2f4878661b65",
   "metadata": {},
   "source": [
    "## Fazit Noise Level 15\n",
    "\n",
    "Durch das Erhöhen des Noise Levels auf 15 wird die Klassifikationsaufgabe deutlich schwieriger, da sich die Klassen stärker überlappen. In allen getesteten Konfigurationen steigt der Test-Loss im Vergleich zu den rauschfreien Daten, und die Entscheidungsgrenzen werden sichtbar unruhiger und weniger klar.\n",
    "\n",
    "Modelle mit wenigen versteckten Schichten bzw. Neuronen sind unter hohem Noise nicht mehr in der Lage, die komplexe Struktur der Daten zuverlässig zu erfassen und zeigen Underfitting. Netzwerke mit mehr Schichten und höherer Kapazität können die Struktur zwar besser approximieren, neigen jedoch dazu, sich stärker an das Rauschen anzupassen, was zu instabilen Lernkurven und teilweise Overfitting führt.\n",
    "\n",
    "Die Wahl der Aktivierungsfunktion beeinflusst vor allem die Stabilität des Lernprozesses:\n",
    "- ReLU lernt schneller, reagiert jedoch empfindlicher auf stark verrauschte Daten.\n",
    "- Tanh zeigt meist glattere Entscheidungsgrenzen und ein stabileres Lernverhalten.\n",
    "- Sigmoid konvergiert langsamer und liefert bei hohem Noise insgesamt die schwächsten Ergebnisse.\n",
    "\n",
    "Insgesamt zeigt sich, dass bei stark verrauschten Daten nicht nur die Modellkomplexität, sondern auch die Wahl einer geeigneten Aktivierungsfunktion entscheidend für die Generalisierungsfähigkeit des Modells ist. Eine höhere Netzkapazität allein führt nicht zwangsläufig zu besseren Ergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706c108-b9e1-40bc-bc7b-bbf5040ba124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e79315-34a5-4441-a166-f82fb73b92cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4957e-6254-4c11-b5cf-32f1168c0df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
